## Recent Advances in Physics-Informed Large Language Models (LLMs)

### Introduction
Physics-Informed Large Language Models (LLMs) represent an innovative integration of machine learning with physical sciences. These models leverage the structure and principles of physical laws to enhance their predictive accuracy and efficiency. Here, we explore some of the most recent advances in this rapidly evolving field.

### Recent Publications
- Lin, F., Liu, J., Li, X., Zhao, S., Zhao, B., Ma, H. and Zhang, X., 2024. PE-GPT: A Physics-Informed Interactive Large Language Model for Power Converter Modulation Design. arXiv preprint arXiv:2403.14059. [Link](https://arxiv.org/abs/2403.14059)
  ![image](https://github.com/qiaosun22/AwesomePhysicsInformedLLMs/assets/136222260/3b649ee5-1c36-413e-b8ad-11b75fb44693)
  The paper proposes PE-GPT, a custom-tailored large language model uniquely adapted for power converter modulation design. By harnessing in-context learning and specialized tiered physics-informed neural networks, PE-GPT guides users through text-based dialogues, recommending actionable modulation parameters.


### Literature Reviews
#### Physics-Informed Neural Networks (PINNs)

- Raissi, Maziar, Paris Perdikaris, and George Em Karniadakis. "Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations." arXiv preprint arXiv:1711.10561 (2017). [link](Raissi, M., Perdikaris, P., & Karniadakis, G. E. (2017). Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations. arXiv preprint arXiv:1711.10561.)

- Raissi, Maziar, Paris Perdikaris, and George Em Karniadakis. "Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations." arXiv preprint arXiv:1711.10566 (2017). [link](https://arxiv.org/pdf/1711.10566)
  
- Raissi, Maziar, Paris Perdikaris, and George E. Karniadakis. "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations." Journal of Computational Physics 378 (2019): 686-707. [link](https://faculty.sites.iastate.edu/hliu/files/inline-files/PINN_RPK_2019_1.pdf) 

- Thais, S., Calafiura, P., Chachamis, G., DeZoort, G., Duarte, J., Ganguly, S., ... & Terao, K. (2022). Graph neural networks in particle physics: Implementations, innovations, and challenges. arXiv preprint arXiv:2203.12852. [link](https://arxiv.org/pdf/2203.12852)

- Daw, A., Karpatne, A., Watkins, W. D., Read, J. S., & Kumar, V. (2022). Physics-guided neural networks (pgnn): An application in lake temperature modeling. In Knowledge Guided Machine Learning (pp. 353-372). Chapman and Hall/CRC. [link](https://arxiv.org/pdf/1710.11431)
  

- Chen, Yanlai, and Shawn Koohy. "Gpt-pinn: Generative pre-trained physics-informed neural networks toward non-intrusive meta-learning of parametric pdes." Finite Elements in Analysis and Design 228 (2024): 104047. [link](https://arxiv.org/pdf/2303.14878)


#### Video Language Planning
- Du, Y., Yang, M., Florence, P., Xia, F., Wahid, A., Ichter, B., ... & Tompson, J. (2023). [link](https://arxiv.org/pdf/2310.10625)

#### Neural Symbolics
- Hsu, J., Mao, J., Tenenbaum, J., & Wu, J. (2024). What’s left? concept grounding with logic-enhanced foundation models. Advances in Neural Information Processing Systems, 36. [link](https://arxiv.org/pdf/2404.19696)
- Liu, W., Chen, G., Hsu, J., Mao, J., & Wu, J. (2024). Learning Planning Abstractions from Language. arXiv preprint arXiv:2405.03864. [link](https://openreview.net/pdf?id=3UWuFoksGb)
- Feng, C., Hsu, J., Liu, W., & Wu, J. (2024). Naturally supervised 3d visual grounding with language-regularized concept learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 13269-13278). [link](https://arxiv.org/pdf/2404.19696)
- Zhen, H., Qiu, X., Chen, P., Yang, J., Yan, X., Du, Y., ... & Gan, C. (2024). 3d-vla: A 3d vision-language-action generative world model. arXiv preprint arXiv:2403.09631. [link](https://arxiv.org/pdf/2403.09631)
- Hsu, J., Mao, J., & Wu, J. (2023). Ns3d: Neuro-symbolic grounding of 3d objects and relations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 2614-2623). [link](https://openaccess.thecvf.com/content/CVPR2023/papers/Hsu_NS3D_Neuro-Symbolic_Grounding_of_3D_Objects_and_Relations_CVPR_2023_paper.pdf)
#### Energy-Based Models
- Du, Y., Mao, J., & Tenenbaum, J. B. Learning Iterative Reasoning through Energy Diffusion. In Forty-first International Conference on Machine Learning. [link](https://arxiv.org/pdf/2406.11179v1)
- Du, Yilun, et al. "Learning iterative reasoning through energy minimization." International Conference on Machine Learning. PMLR, 2022. [link](https://proceedings.mlr.press/v162/du22d/du22d.pdf) \
  They propose Energy-Based Models as a methodology for reasoning, with a learning an energy landscape.

#### Read World Simulators
- Yang, M., Du, Y., Ghasemipour, K., Tompson, J., Schuurmans, D., & Abbeel, P. (2023). Learning interactive real-world simulators. arXiv preprint arXiv:2310.06114. [link](https://arxiv.org/pdf/2310.06114)

#### Compositional Generative Modeling
- Du, Y., & Kaelbling, L. (2024). Compositional Generative Modeling: A Single Model is Not All You Need. arXiv preprint arXiv:2402.01103. [link](https://arxiv.org/pdf/2402.01103) 
#### Universal Policies
- Du, Y., Yang, S., Dai, B., Dai, H., Nachum, O., Tenenbaum, J., ... & Abbeel, P. (2024). Learning universal policies via text-guided video generation. Advances in Neural Information Processing Systems, 36. [link](https://arxiv.org/pdf/2302.00111)

### Lectures
- [Physics-informed machine learning –
Hype or new trend in computational engineering?](https://homepage.tudelft.nl/y95n9/files/presentations/icsm2023.pdf)

- [Physics Informed Neural Networks (PINNs) [Physics Informed Machine Learning](https://www.youtube.com/watch?v=-zrY7P2dVC4&t=1326s)

### Media & Web Resouces
Alexander Leschik. [Forecasting with Physics Informed Machine Learning (PIML)](https://medium.com/@royaltokens/forecasting-with-physics-informed-machine-learning-piml-670a6e168293)


### Milestones

1. **Hybrid Models Combining Physics and Data-Driven Approaches** (2017)
   - **Physics-Guided Neural Networks (PGNNs)**: PGNNs incorporate physical laws directly into the training process, reducing the need for large datasets and enhancing model interpretability.
   - **Differentiable Physics**: This approach integrates differentiable physics solvers with neural networks, allowing models to learn physical dynamics more effectively.

2. **Physics-Informed Neural Networks (PINNs)** (2019)
   - **Improved Training Algorithms**: Advances in optimization techniques, such as adaptive learning rates and physics-based regularization methods, have significantly improved the training efficiency of PINNs.
   - **Multi-Scale and Multi-Physics Problems**: Recent work has extended PINNs to handle complex multi-scale and multi-physics problems, making them applicable to a wider range of scientific and engineering challenges.

3. **Graph Neural Networks (GNNs) for Physical Systems** (2022)
   - **Graph-based Representations**: GNNs have been utilized to model the interactions within physical systems, such as molecular dynamics and material science, by representing systems as graphs where nodes correspond to particles or atoms and edges represent interactions.
   - **Scalable and Efficient Computations**: Improvements in GNN architectures and training methods have enabled the scalable and efficient simulation of large physical systems.

### Challenges and Future Directions

1. **Scalability and Generalization**
   - **Scalability**: Ensuring that physics-informed LLMs can scale to handle large and complex systems remains a significant challenge.
   - **Generalization**: Developing models that generalize well across different physical systems and conditions is crucial for broader applicability.

2. **Interdisciplinary Collaboration**
   - **Collaboration**: Continued progress will require close collaboration between domain experts in physics, machine learning, and high-performance computing.

3. **Model Interpretability**
   - **Interpretability**: Enhancing the interpretability of physics-informed LLMs is essential for gaining insights into physical phenomena and for their acceptance in scientific and engineering communities.

### Conclusion

The field of physics-informed large language models is rapidly advancing, driven by innovations in model architectures, training techniques, and applications across various scientific domains. These models hold great promise for accelerating scientific discovery and engineering innovation by providing powerful tools that blend the strengths of machine learning with the rigor of physical laws.

As research continues, addressing challenges related to scalability, generalization, and interpretability will be key to unlocking the full potential of physics-informed LLMs. The future of this interdisciplinary field looks promising, with exciting opportunities for breakthroughs in both fundamental science and practical applications.


